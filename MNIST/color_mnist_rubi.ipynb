{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "class BiasedMNIST(MNIST):\n",
    "    \"\"\"A base class for Biased-MNIST.\n",
    "    We manually select ten colours to synthetic colour bias. (See `COLOUR_MAP` for the colour configuration)\n",
    "    Usage is exactly same as torchvision MNIST dataset class.\n",
    "\n",
    "    You have two paramters to control the level of bias.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        path to MNIST dataset.\n",
    "    data_label_correlation : float, default=1.0\n",
    "        Here, each class has the pre-defined colour (bias).\n",
    "        data_label_correlation, or `rho` controls the level of the dataset bias.\n",
    "\n",
    "        A sample is coloured with\n",
    "            - the pre-defined colour with probability `rho`,\n",
    "            - coloured with one of the other colours with probability `1 - rho`.\n",
    "              The number of ``other colours'' is controlled by `n_confusing_labels` (default: 9).\n",
    "        Note that the colour is injected into the background of the image (see `_binary_to_colour`).\n",
    "\n",
    "        Hence, we have\n",
    "            - Perfectly biased dataset with rho=1.0\n",
    "            - Perfectly unbiased with rho=0.1 (1/10) ==> our ``unbiased'' setting in the test time.\n",
    "        In the paper, we explore the high correlations but with small hints, e.g., rho=0.999.\n",
    "\n",
    "    n_confusing_labels : int, default=9\n",
    "        In the real-world cases, biases are not equally distributed, but highly unbalanced.\n",
    "        We mimic the unbalanced biases by changing the number of confusing colours for each class.\n",
    "        In the paper, we use n_confusing_labels=9, i.e., during training, the model can observe\n",
    "        all colours for each class. However, you can make the problem harder by setting smaller n_confusing_labels, e.g., 2.\n",
    "        We suggest to researchers considering this benchmark for future researches.\n",
    "    \"\"\"\n",
    "\n",
    "    COLOUR_MAP = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [225, 225, 0], [225, 0, 225],\n",
    "                  [0, 255, 255], [255, 128, 0], [255, 0, 128], [128, 0, 255], [128, 128, 128]]\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9):\n",
    "        super().__init__(root, train=train, transform=transform,\n",
    "                         target_transform=target_transform,\n",
    "                         download=download)\n",
    "        self.random = True\n",
    "\n",
    "        self.data_label_correlation = data_label_correlation\n",
    "        self.n_confusing_labels = n_confusing_labels\n",
    "        self.data, self.targets, self.colored_bg, self.biased_targets = self.build_biased_mnist()\n",
    "\n",
    "        indices = np.arange(len(self.data))\n",
    "        self._shuffle(indices)\n",
    "\n",
    "        self.data = self.data[indices].numpy()\n",
    "        self.colored_bg = self.colored_bg[indices].numpy()\n",
    "        self.targets = self.targets[indices]\n",
    "        self.biased_targets = self.biased_targets[indices]\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, 'processed')\n",
    "\n",
    "    def _shuffle(self, iteratable):\n",
    "        if self.random:\n",
    "            np.random.shuffle(iteratable)\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _update_bias_indices(self, bias_indices, label):\n",
    "        if self.n_confusing_labels > 9 or self.n_confusing_labels < 1:\n",
    "            raise ValueError(self.n_confusing_labels)\n",
    "\n",
    "        indices = np.where((self.targets == label).numpy())[0]\n",
    "        self._shuffle(indices)\n",
    "        indices = torch.LongTensor(indices)\n",
    "\n",
    "        n_samples = len(indices)\n",
    "        n_correlated_samples = int(n_samples * self.data_label_correlation)\n",
    "        n_decorrelated_per_class = int(np.ceil((n_samples - n_correlated_samples) / (self.n_confusing_labels)))\n",
    "\n",
    "        correlated_indices = indices[:n_correlated_samples]\n",
    "        bias_indices[label] = torch.cat([bias_indices[label], correlated_indices])\n",
    "\n",
    "        decorrelated_indices = torch.split(indices[n_correlated_samples:], n_decorrelated_per_class)\n",
    "\n",
    "        other_labels = [_label % 10 for _label in range(label + 1, label + 1 + self.n_confusing_labels)]\n",
    "        self._shuffle(other_labels)\n",
    "\n",
    "        for idx, _indices in enumerate(decorrelated_indices):\n",
    "            _label = other_labels[idx]\n",
    "            bias_indices[_label] = torch.cat([bias_indices[_label], _indices])\n",
    "\n",
    "    def build_biased_mnist(self):\n",
    "        \"\"\"Build biased MNIST.\n",
    "        \"\"\"\n",
    "        n_labels = self.targets.max().item() + 1\n",
    "\n",
    "        bias_indices = {label: torch.LongTensor() for label in range(n_labels)}\n",
    "        for label in range(n_labels):\n",
    "            self._update_bias_indices(bias_indices, label)\n",
    "\n",
    "        data = torch.ByteTensor()\n",
    "        targets = torch.LongTensor()\n",
    "        colored_bg = torch.ByteTensor()\n",
    "        biased_targets = []\n",
    "\n",
    "        for bias_label, indices in bias_indices.items():\n",
    "            (_data, _colored_bg), _targets = self._make_biased_mnist(indices, bias_label)\n",
    "            data = torch.cat([data, _data])\n",
    "            colored_bg = torch.cat([colored_bg, _colored_bg])\n",
    "            targets = torch.cat([targets, _targets])\n",
    "            biased_targets.extend([bias_label] * len(indices))\n",
    "\n",
    "        biased_targets = torch.LongTensor(biased_targets)\n",
    "        return data, targets, colored_bg, biased_targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        colored_bg = self.colored_bg[index]\n",
    "        img = Image.fromarray(img.astype(np.uint8), mode='RGB')\n",
    "        bias = Image.fromarray(colored_bg.astype(np.uint8), mode='RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            bias = self.transform(bias)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        img = np.asarray(img)\n",
    "        bias = np.asarray(bias)\n",
    "        \n",
    "        label = torch.zeros(10)\n",
    "        label.scatter_(0, target, 1)\n",
    "\n",
    "        return img, target, bias, int(self.biased_targets[index])\n",
    "\n",
    "\n",
    "class ColourBiasedMNIST(BiasedMNIST):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9):\n",
    "        super(ColourBiasedMNIST, self).__init__(root, train=train, transform=transform,\n",
    "                                                target_transform=target_transform,\n",
    "                                                download=download,\n",
    "                                                data_label_correlation=data_label_correlation,\n",
    "                                                n_confusing_labels=n_confusing_labels)\n",
    "\n",
    "    def _binary_to_colour(self, data, colour):\n",
    "        fg_data = torch.zeros_like(data)\n",
    "        fg_data[data != 0] = 255\n",
    "        fg_data[data == 0] = 0\n",
    "        fg_data = torch.stack([fg_data, fg_data, fg_data], dim=1)\n",
    "\n",
    "        bg_data = torch.zeros_like(data)\n",
    "        bg_data[data == 0] = 1\n",
    "        bg_data[data != 0] = 0\n",
    "        bg_data = torch.stack([bg_data, bg_data, bg_data], dim=3)\n",
    "        bg_data = bg_data * torch.ByteTensor(colour)\n",
    "        \n",
    "        \n",
    "        colored_bg = (bg_data + 1 - bg_data) * torch.ByteTensor(colour)\n",
    "        \n",
    "        bg_data = bg_data.permute(0, 3, 1, 2)\n",
    "        data = fg_data + bg_data\n",
    "        \n",
    "        return data.permute(0, 2, 3, 1), colored_bg\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        return self._binary_to_colour(self.data[indices], self.COLOUR_MAP[label]), self.targets[indices]\n",
    "\n",
    "\n",
    "def get_biased_mnist_dataloader(root, batch_size, data_label_correlation,\n",
    "                                n_confusing_labels=9, train=True, num_workers=4):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                             std=(0.5, 0.5, 0.5))])\n",
    "    dataset = ColourBiasedMNIST(root, train=train, transform=transform,\n",
    "                                download=True, data_label_correlation=data_label_correlation,\n",
    "                                n_confusing_labels=n_confusing_labels)\n",
    "    dataloader = data.DataLoader(dataset=dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnist_train = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0.990,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=True)\n",
    "cmnist_val_bias = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0.990,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=False)\n",
    "cmnist_val_unbias = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0.1,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=False)\n",
    "cmnist_val_origin = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets, bias, _) in enumerate(cmnist_train):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 28, 28])\n",
      "tensor(9)\n",
      "torch.Size([128, 3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(targets[3])\n",
    "print(bias.shape)\n",
    "nhw_img = np.transpose(features[3], axes=(1, 2, 0))\n",
    "plt.imshow(nhw_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bg = np.transpose(bias[3], axes=(1, 2, 0))\n",
    "plt.imshow(bg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # because MNIST is already 1x1 here:\n",
    "        # disable avg pooling\n",
    "        #x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet18(num_classes):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[2, 2, 2, 2],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, kernel_size=7, feature_pos='post'):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        layers = [ \n",
    "            nn.Conv2d(3, 16, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        self.extracter = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if feature_pos not in ['pre', 'post', 'logits']:\n",
    "            raise ValueError(feature_pos)\n",
    "\n",
    "        self.feature_pos = feature_pos\n",
    "\n",
    "    def forward(self, x, logits_only=False):\n",
    "        pre_gap_feats = self.extracter(x)\n",
    "        post_gap_feats = self.avgpool(pre_gap_feats)\n",
    "        post_gap_feats = torch.flatten(post_gap_feats, 1)\n",
    "        logits = self.fc(post_gap_feats)\n",
    "\n",
    "        if logits_only:\n",
    "            return logits\n",
    "\n",
    "        elif self.feature_pos == 'pre':\n",
    "            feats = pre_gap_feats\n",
    "        elif self.feature_pos == 'post':\n",
    "            feats = post_gap_feats\n",
    "        else:\n",
    "            feats = logits\n",
    "        return logits, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = resnet18(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "# model = SimpleConvNet(kernel_size=7, feature_pos='post').to(DEVICE)\n",
    "\n",
    "# model_c = SimpleConvNet(kernel_size=1, feature_pos='post').to(DEVICE)\n",
    "\n",
    "model_c = resnet18(NUM_CLASSES)\n",
    "model_c.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': model_c.parameters()}], lr=LEARNING_RATE)  \n",
    "# optimizer_c = torch.optim.Adam(model_c.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets, bias, _) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "#         targets = torch.argmax(targets, 1).to(device)\n",
    "        bias = bias.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "#         logits, probas = model(bias)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/025 | Batch 0000/0469 | Cost: 4.8536\n",
      "Epoch: 001/025 | Batch 0050/0469 | Cost: 0.0331\n",
      "Epoch: 001/025 | Batch 0100/0469 | Cost: 0.2387\n",
      "Epoch: 001/025 | Batch 0150/0469 | Cost: 1.0530\n",
      "Epoch: 001/025 | Batch 0200/0469 | Cost: 0.2999\n",
      "Epoch: 001/025 | Batch 0250/0469 | Cost: 0.0681\n",
      "Epoch: 001/025 | Batch 0300/0469 | Cost: 0.0133\n",
      "Epoch: 001/025 | Batch 0350/0469 | Cost: 0.1892\n",
      "Epoch: 001/025 | Batch 0400/0469 | Cost: 0.0274\n",
      "Epoch: 001/025 | Batch 0450/0469 | Cost: 0.3826\n",
      "Epoch: 001/025 | Train: 58.740%\n",
      "Time elapsed: 0.79 min\n",
      "Epoch: 002/025 | Batch 0000/0469 | Cost: 0.3621\n",
      "Epoch: 002/025 | Batch 0050/0469 | Cost: 0.0937\n",
      "Epoch: 002/025 | Batch 0100/0469 | Cost: 0.1132\n",
      "Epoch: 002/025 | Batch 0150/0469 | Cost: 0.2503\n",
      "Epoch: 002/025 | Batch 0200/0469 | Cost: 0.1531\n",
      "Epoch: 002/025 | Batch 0250/0469 | Cost: 0.0701\n",
      "Epoch: 002/025 | Batch 0300/0469 | Cost: 0.0110\n",
      "Epoch: 002/025 | Batch 0350/0469 | Cost: 0.2687\n",
      "Epoch: 002/025 | Batch 0400/0469 | Cost: 0.0168\n",
      "Epoch: 002/025 | Batch 0450/0469 | Cost: 0.0815\n",
      "Epoch: 002/025 | Train: 77.410%\n",
      "Time elapsed: 1.58 min\n",
      "Epoch: 003/025 | Batch 0000/0469 | Cost: 0.1283\n",
      "Epoch: 003/025 | Batch 0050/0469 | Cost: 0.2034\n",
      "Epoch: 003/025 | Batch 0100/0469 | Cost: 0.2434\n",
      "Epoch: 003/025 | Batch 0150/0469 | Cost: 0.0183\n",
      "Epoch: 003/025 | Batch 0200/0469 | Cost: 0.0685\n",
      "Epoch: 003/025 | Batch 0250/0469 | Cost: 0.0071\n",
      "Epoch: 003/025 | Batch 0300/0469 | Cost: 0.1423\n",
      "Epoch: 003/025 | Batch 0350/0469 | Cost: 0.1154\n",
      "Epoch: 003/025 | Batch 0400/0469 | Cost: 0.0137\n",
      "Epoch: 003/025 | Batch 0450/0469 | Cost: 0.1526\n",
      "Epoch: 003/025 | Train: 76.400%\n",
      "Time elapsed: 2.40 min\n",
      "Epoch: 004/025 | Batch 0000/0469 | Cost: 0.0332\n",
      "Epoch: 004/025 | Batch 0050/0469 | Cost: 0.1342\n",
      "Epoch: 004/025 | Batch 0100/0469 | Cost: 0.2094\n",
      "Epoch: 004/025 | Batch 0150/0469 | Cost: 0.0616\n",
      "Epoch: 004/025 | Batch 0200/0469 | Cost: 0.2594\n",
      "Epoch: 004/025 | Batch 0250/0469 | Cost: 0.4341\n",
      "Epoch: 004/025 | Batch 0300/0469 | Cost: 0.0750\n",
      "Epoch: 004/025 | Batch 0350/0469 | Cost: 0.1395\n",
      "Epoch: 004/025 | Batch 0400/0469 | Cost: 0.2258\n",
      "Epoch: 004/025 | Batch 0450/0469 | Cost: 0.0084\n",
      "Epoch: 004/025 | Train: 84.740%\n",
      "Time elapsed: 3.22 min\n",
      "Epoch: 005/025 | Batch 0000/0469 | Cost: 0.1401\n",
      "Epoch: 005/025 | Batch 0050/0469 | Cost: 0.0831\n",
      "Epoch: 005/025 | Batch 0100/0469 | Cost: 0.1717\n",
      "Epoch: 005/025 | Batch 0150/0469 | Cost: 0.0788\n",
      "Epoch: 005/025 | Batch 0200/0469 | Cost: 0.1421\n",
      "Epoch: 005/025 | Batch 0250/0469 | Cost: 0.0151\n",
      "Epoch: 005/025 | Batch 0300/0469 | Cost: 0.0647\n",
      "Epoch: 005/025 | Batch 0350/0469 | Cost: 0.0707\n",
      "Epoch: 005/025 | Batch 0400/0469 | Cost: 0.0630\n",
      "Epoch: 005/025 | Batch 0450/0469 | Cost: 0.0108\n",
      "Epoch: 005/025 | Train: 80.960%\n",
      "Time elapsed: 4.04 min\n",
      "Epoch: 006/025 | Batch 0000/0469 | Cost: 0.0123\n",
      "Epoch: 006/025 | Batch 0050/0469 | Cost: 0.0733\n",
      "Epoch: 006/025 | Batch 0100/0469 | Cost: 0.0567\n",
      "Epoch: 006/025 | Batch 0150/0469 | Cost: 0.3597\n",
      "Epoch: 006/025 | Batch 0200/0469 | Cost: 0.0115\n",
      "Epoch: 006/025 | Batch 0250/0469 | Cost: 0.2241\n",
      "Epoch: 006/025 | Batch 0300/0469 | Cost: 0.0853\n",
      "Epoch: 006/025 | Batch 0350/0469 | Cost: 0.0997\n",
      "Epoch: 006/025 | Batch 0400/0469 | Cost: 0.0174\n",
      "Epoch: 006/025 | Batch 0450/0469 | Cost: 0.0580\n",
      "Epoch: 006/025 | Train: 84.090%\n",
      "Time elapsed: 4.80 min\n",
      "Epoch: 007/025 | Batch 0000/0469 | Cost: 0.0884\n",
      "Epoch: 007/025 | Batch 0050/0469 | Cost: 0.0090\n",
      "Epoch: 007/025 | Batch 0100/0469 | Cost: 0.0124\n",
      "Epoch: 007/025 | Batch 0150/0469 | Cost: 0.0126\n",
      "Epoch: 007/025 | Batch 0200/0469 | Cost: 0.0199\n",
      "Epoch: 007/025 | Batch 0250/0469 | Cost: 0.0599\n",
      "Epoch: 007/025 | Batch 0300/0469 | Cost: 0.2085\n",
      "Epoch: 007/025 | Batch 0350/0469 | Cost: 0.0771\n",
      "Epoch: 007/025 | Batch 0400/0469 | Cost: 0.1153\n",
      "Epoch: 007/025 | Batch 0450/0469 | Cost: 0.1170\n",
      "Epoch: 007/025 | Train: 83.150%\n",
      "Time elapsed: 5.62 min\n",
      "Epoch: 008/025 | Batch 0000/0469 | Cost: 0.1653\n",
      "Epoch: 008/025 | Batch 0050/0469 | Cost: 0.1181\n",
      "Epoch: 008/025 | Batch 0100/0469 | Cost: 0.0687\n",
      "Epoch: 008/025 | Batch 0150/0469 | Cost: 0.0160\n",
      "Epoch: 008/025 | Batch 0200/0469 | Cost: 0.0719\n",
      "Epoch: 008/025 | Batch 0250/0469 | Cost: 0.1184\n",
      "Epoch: 008/025 | Batch 0300/0469 | Cost: 0.1536\n",
      "Epoch: 008/025 | Batch 0350/0469 | Cost: 0.1141\n",
      "Epoch: 008/025 | Batch 0400/0469 | Cost: 0.0756\n",
      "Epoch: 008/025 | Batch 0450/0469 | Cost: 0.0310\n",
      "Epoch: 008/025 | Train: 85.690%\n",
      "Time elapsed: 6.43 min\n",
      "Epoch: 009/025 | Batch 0000/0469 | Cost: 0.0750\n",
      "Epoch: 009/025 | Batch 0050/0469 | Cost: 0.1973\n",
      "Epoch: 009/025 | Batch 0100/0469 | Cost: 0.2511\n",
      "Epoch: 009/025 | Batch 0150/0469 | Cost: 0.0082\n",
      "Epoch: 009/025 | Batch 0200/0469 | Cost: 0.3004\n",
      "Epoch: 009/025 | Batch 0250/0469 | Cost: 0.1903\n",
      "Epoch: 009/025 | Batch 0300/0469 | Cost: 0.0834\n",
      "Epoch: 009/025 | Batch 0350/0469 | Cost: 0.1352\n",
      "Epoch: 009/025 | Batch 0400/0469 | Cost: 0.0120\n",
      "Epoch: 009/025 | Batch 0450/0469 | Cost: 0.0806\n",
      "Epoch: 009/025 | Train: 86.750%\n",
      "Time elapsed: 7.23 min\n",
      "Epoch: 010/025 | Batch 0000/0469 | Cost: 0.1748\n",
      "Epoch: 010/025 | Batch 0050/0469 | Cost: 0.0086\n",
      "Epoch: 010/025 | Batch 0100/0469 | Cost: 0.0582\n",
      "Epoch: 010/025 | Batch 0150/0469 | Cost: 0.1365\n",
      "Epoch: 010/025 | Batch 0200/0469 | Cost: 0.1358\n",
      "Epoch: 010/025 | Batch 0250/0469 | Cost: 0.2631\n",
      "Epoch: 010/025 | Batch 0300/0469 | Cost: 0.1743\n",
      "Epoch: 010/025 | Batch 0350/0469 | Cost: 0.0290\n",
      "Epoch: 010/025 | Batch 0400/0469 | Cost: 0.0659\n",
      "Epoch: 010/025 | Batch 0450/0469 | Cost: 0.0074\n",
      "Epoch: 010/025 | Train: 88.780%\n",
      "Time elapsed: 7.98 min\n",
      "Epoch: 011/025 | Batch 0000/0469 | Cost: 0.1302\n",
      "Epoch: 011/025 | Batch 0050/0469 | Cost: 0.1192\n",
      "Epoch: 011/025 | Batch 0100/0469 | Cost: 0.0755\n",
      "Epoch: 011/025 | Batch 0150/0469 | Cost: 0.1413\n",
      "Epoch: 011/025 | Batch 0200/0469 | Cost: 0.1637\n",
      "Epoch: 011/025 | Batch 0250/0469 | Cost: 0.2177\n",
      "Epoch: 011/025 | Batch 0300/0469 | Cost: 0.0834\n",
      "Epoch: 011/025 | Batch 0350/0469 | Cost: 0.0170\n",
      "Epoch: 011/025 | Batch 0400/0469 | Cost: 0.0626\n",
      "Epoch: 011/025 | Batch 0450/0469 | Cost: 0.0206\n",
      "Epoch: 011/025 | Train: 89.480%\n",
      "Time elapsed: 8.76 min\n",
      "Epoch: 012/025 | Batch 0000/0469 | Cost: 0.0156\n",
      "Epoch: 012/025 | Batch 0050/0469 | Cost: 0.0128\n",
      "Epoch: 012/025 | Batch 0100/0469 | Cost: 0.0565\n",
      "Epoch: 012/025 | Batch 0150/0469 | Cost: 0.0859\n",
      "Epoch: 012/025 | Batch 0200/0469 | Cost: 0.0062\n",
      "Epoch: 012/025 | Batch 0250/0469 | Cost: 0.2536\n",
      "Epoch: 012/025 | Batch 0300/0469 | Cost: 0.0694\n",
      "Epoch: 012/025 | Batch 0350/0469 | Cost: 0.2948\n",
      "Epoch: 012/025 | Batch 0400/0469 | Cost: 0.0672\n",
      "Epoch: 012/025 | Batch 0450/0469 | Cost: 0.2549\n",
      "Epoch: 012/025 | Train: 89.270%\n",
      "Time elapsed: 9.54 min\n",
      "Epoch: 013/025 | Batch 0000/0469 | Cost: 0.2049\n",
      "Epoch: 013/025 | Batch 0050/0469 | Cost: 0.0626\n",
      "Epoch: 013/025 | Batch 0100/0469 | Cost: 0.1197\n",
      "Epoch: 013/025 | Batch 0150/0469 | Cost: 0.0658\n",
      "Epoch: 013/025 | Batch 0200/0469 | Cost: 0.1126\n",
      "Epoch: 013/025 | Batch 0250/0469 | Cost: 0.1290\n",
      "Epoch: 013/025 | Batch 0300/0469 | Cost: 0.1713\n",
      "Epoch: 013/025 | Batch 0350/0469 | Cost: 0.1027\n",
      "Epoch: 013/025 | Batch 0400/0469 | Cost: 0.0105\n",
      "Epoch: 013/025 | Batch 0450/0469 | Cost: 0.2434\n",
      "Epoch: 013/025 | Train: 88.830%\n",
      "Time elapsed: 10.32 min\n",
      "Epoch: 014/025 | Batch 0000/0469 | Cost: 0.5142\n",
      "Epoch: 014/025 | Batch 0050/0469 | Cost: 0.1501\n",
      "Epoch: 014/025 | Batch 0100/0469 | Cost: 0.0301\n",
      "Epoch: 014/025 | Batch 0150/0469 | Cost: 0.0117\n",
      "Epoch: 014/025 | Batch 0200/0469 | Cost: 0.0873\n",
      "Epoch: 014/025 | Batch 0250/0469 | Cost: 0.0709\n",
      "Epoch: 014/025 | Batch 0300/0469 | Cost: 0.0216\n",
      "Epoch: 014/025 | Batch 0350/0469 | Cost: 0.0742\n",
      "Epoch: 014/025 | Batch 0400/0469 | Cost: 0.1394\n",
      "Epoch: 014/025 | Batch 0450/0469 | Cost: 0.0702\n",
      "Epoch: 014/025 | Train: 89.890%\n",
      "Time elapsed: 11.06 min\n",
      "Epoch: 015/025 | Batch 0000/0469 | Cost: 0.0621\n",
      "Epoch: 015/025 | Batch 0050/0469 | Cost: 0.1270\n",
      "Epoch: 015/025 | Batch 0100/0469 | Cost: 0.2683\n",
      "Epoch: 015/025 | Batch 0150/0469 | Cost: 0.0088\n",
      "Epoch: 015/025 | Batch 0200/0469 | Cost: 0.0622\n",
      "Epoch: 015/025 | Batch 0250/0469 | Cost: 0.0858\n",
      "Epoch: 015/025 | Batch 0300/0469 | Cost: 0.0246\n",
      "Epoch: 015/025 | Batch 0350/0469 | Cost: 0.1237\n",
      "Epoch: 015/025 | Batch 0400/0469 | Cost: 0.0647\n",
      "Epoch: 015/025 | Batch 0450/0469 | Cost: 0.1573\n",
      "Epoch: 015/025 | Train: 88.450%\n",
      "Time elapsed: 11.79 min\n",
      "Epoch: 016/025 | Batch 0000/0469 | Cost: 0.0758\n",
      "Epoch: 016/025 | Batch 0050/0469 | Cost: 0.1493\n",
      "Epoch: 016/025 | Batch 0100/0469 | Cost: 0.1274\n",
      "Epoch: 016/025 | Batch 0150/0469 | Cost: 0.0739\n",
      "Epoch: 016/025 | Batch 0200/0469 | Cost: 0.1220\n",
      "Epoch: 016/025 | Batch 0250/0469 | Cost: 0.0103\n",
      "Epoch: 016/025 | Batch 0300/0469 | Cost: 0.0115\n",
      "Epoch: 016/025 | Batch 0350/0469 | Cost: 0.0079\n",
      "Epoch: 016/025 | Batch 0400/0469 | Cost: 0.0565\n",
      "Epoch: 016/025 | Batch 0450/0469 | Cost: 0.1140\n",
      "Epoch: 016/025 | Train: 88.780%\n",
      "Time elapsed: 12.56 min\n",
      "Epoch: 017/025 | Batch 0000/0469 | Cost: 0.0137\n",
      "Epoch: 017/025 | Batch 0050/0469 | Cost: 0.2548\n",
      "Epoch: 017/025 | Batch 0100/0469 | Cost: 0.0195\n",
      "Epoch: 017/025 | Batch 0150/0469 | Cost: 0.1732\n",
      "Epoch: 017/025 | Batch 0200/0469 | Cost: 0.0755\n",
      "Epoch: 017/025 | Batch 0250/0469 | Cost: 0.0096\n",
      "Epoch: 017/025 | Batch 0300/0469 | Cost: 0.1101\n",
      "Epoch: 017/025 | Batch 0350/0469 | Cost: 0.0790\n",
      "Epoch: 017/025 | Batch 0400/0469 | Cost: 0.1360\n",
      "Epoch: 017/025 | Batch 0450/0469 | Cost: 0.1392\n",
      "Epoch: 017/025 | Train: 85.870%\n",
      "Time elapsed: 13.25 min\n",
      "Epoch: 018/025 | Batch 0000/0469 | Cost: 0.1279\n",
      "Epoch: 018/025 | Batch 0050/0469 | Cost: 0.1828\n",
      "Epoch: 018/025 | Batch 0100/0469 | Cost: 0.0097\n",
      "Epoch: 018/025 | Batch 0150/0469 | Cost: 0.1285\n",
      "Epoch: 018/025 | Batch 0200/0469 | Cost: 0.0989\n",
      "Epoch: 018/025 | Batch 0250/0469 | Cost: 0.1897\n",
      "Epoch: 018/025 | Batch 0300/0469 | Cost: 0.0751\n",
      "Epoch: 018/025 | Batch 0350/0469 | Cost: 0.0626\n",
      "Epoch: 018/025 | Batch 0400/0469 | Cost: 0.0106\n",
      "Epoch: 018/025 | Batch 0450/0469 | Cost: 0.0832\n",
      "Epoch: 018/025 | Train: 87.460%\n",
      "Time elapsed: 14.02 min\n",
      "Epoch: 019/025 | Batch 0000/0469 | Cost: 0.0102\n",
      "Epoch: 019/025 | Batch 0050/0469 | Cost: 0.0647\n",
      "Epoch: 019/025 | Batch 0100/0469 | Cost: 0.1228\n",
      "Epoch: 019/025 | Batch 0150/0469 | Cost: 0.0091\n",
      "Epoch: 019/025 | Batch 0200/0469 | Cost: 0.1802\n",
      "Epoch: 019/025 | Batch 0250/0469 | Cost: 0.0096\n",
      "Epoch: 019/025 | Batch 0300/0469 | Cost: 0.0127\n",
      "Epoch: 019/025 | Batch 0350/0469 | Cost: 0.0126\n",
      "Epoch: 019/025 | Batch 0400/0469 | Cost: 0.1882\n",
      "Epoch: 019/025 | Batch 0450/0469 | Cost: 0.1837\n",
      "Epoch: 019/025 | Train: 86.570%\n",
      "Time elapsed: 14.78 min\n",
      "Epoch: 020/025 | Batch 0000/0469 | Cost: 0.1044\n",
      "Epoch: 020/025 | Batch 0050/0469 | Cost: 0.1437\n",
      "Epoch: 020/025 | Batch 0100/0469 | Cost: 0.0654\n",
      "Epoch: 020/025 | Batch 0150/0469 | Cost: 0.0722\n",
      "Epoch: 020/025 | Batch 0200/0469 | Cost: 0.1635\n",
      "Epoch: 020/025 | Batch 0250/0469 | Cost: 0.0599\n",
      "Epoch: 020/025 | Batch 0300/0469 | Cost: 0.3401\n",
      "Epoch: 020/025 | Batch 0350/0469 | Cost: 0.0105\n",
      "Epoch: 020/025 | Batch 0400/0469 | Cost: 0.0727\n",
      "Epoch: 020/025 | Batch 0450/0469 | Cost: 0.0815\n",
      "Epoch: 020/025 | Train: 89.660%\n",
      "Time elapsed: 15.53 min\n",
      "Epoch: 021/025 | Batch 0000/0469 | Cost: 0.1804\n",
      "Epoch: 021/025 | Batch 0050/0469 | Cost: 0.1928\n",
      "Epoch: 021/025 | Batch 0100/0469 | Cost: 0.1785\n",
      "Epoch: 021/025 | Batch 0150/0469 | Cost: 0.0102\n",
      "Epoch: 021/025 | Batch 0200/0469 | Cost: 0.0724\n",
      "Epoch: 021/025 | Batch 0250/0469 | Cost: 0.1241\n",
      "Epoch: 021/025 | Batch 0300/0469 | Cost: 0.0632\n",
      "Epoch: 021/025 | Batch 0350/0469 | Cost: 0.0084\n",
      "Epoch: 021/025 | Batch 0400/0469 | Cost: 0.0107\n",
      "Epoch: 021/025 | Batch 0450/0469 | Cost: 0.0130\n",
      "Epoch: 021/025 | Train: 89.210%\n",
      "Time elapsed: 16.28 min\n",
      "Epoch: 022/025 | Batch 0000/0469 | Cost: 0.1319\n",
      "Epoch: 022/025 | Batch 0050/0469 | Cost: 0.2474\n",
      "Epoch: 022/025 | Batch 0100/0469 | Cost: 0.1807\n",
      "Epoch: 022/025 | Batch 0150/0469 | Cost: 0.1235\n",
      "Epoch: 022/025 | Batch 0200/0469 | Cost: 0.0916\n",
      "Epoch: 022/025 | Batch 0250/0469 | Cost: 0.1893\n",
      "Epoch: 022/025 | Batch 0300/0469 | Cost: 0.1208\n",
      "Epoch: 022/025 | Batch 0350/0469 | Cost: 0.0085\n",
      "Epoch: 022/025 | Batch 0400/0469 | Cost: 0.1190\n",
      "Epoch: 022/025 | Batch 0450/0469 | Cost: 0.1592\n",
      "Epoch: 022/025 | Train: 87.980%\n",
      "Time elapsed: 17.04 min\n",
      "Epoch: 023/025 | Batch 0000/0469 | Cost: 0.0735\n",
      "Epoch: 023/025 | Batch 0050/0469 | Cost: 0.0706\n",
      "Epoch: 023/025 | Batch 0100/0469 | Cost: 0.0122\n",
      "Epoch: 023/025 | Batch 0150/0469 | Cost: 0.1129\n",
      "Epoch: 023/025 | Batch 0200/0469 | Cost: 0.1190\n",
      "Epoch: 023/025 | Batch 0250/0469 | Cost: 0.0117\n",
      "Epoch: 023/025 | Batch 0300/0469 | Cost: 0.0719\n",
      "Epoch: 023/025 | Batch 0350/0469 | Cost: 0.0609\n",
      "Epoch: 023/025 | Batch 0400/0469 | Cost: 0.2344\n",
      "Epoch: 023/025 | Batch 0450/0469 | Cost: 0.2436\n",
      "Epoch: 023/025 | Train: 91.560%\n",
      "Time elapsed: 17.79 min\n",
      "Epoch: 024/025 | Batch 0000/0469 | Cost: 0.1271\n",
      "Epoch: 024/025 | Batch 0050/0469 | Cost: 0.1183\n",
      "Epoch: 024/025 | Batch 0100/0469 | Cost: 0.0690\n",
      "Epoch: 024/025 | Batch 0150/0469 | Cost: 0.0094\n",
      "Epoch: 024/025 | Batch 0200/0469 | Cost: 0.1148\n",
      "Epoch: 024/025 | Batch 0250/0469 | Cost: 0.0100\n",
      "Epoch: 024/025 | Batch 0300/0469 | Cost: 0.1934\n",
      "Epoch: 024/025 | Batch 0350/0469 | Cost: 0.1214\n",
      "Epoch: 024/025 | Batch 0400/0469 | Cost: 0.1605\n",
      "Epoch: 024/025 | Batch 0450/0469 | Cost: 0.1199\n",
      "Epoch: 024/025 | Train: 85.030%\n",
      "Time elapsed: 18.56 min\n",
      "Epoch: 025/025 | Batch 0000/0469 | Cost: 0.0098\n",
      "Epoch: 025/025 | Batch 0050/0469 | Cost: 0.0668\n",
      "Epoch: 025/025 | Batch 0100/0469 | Cost: 0.0536\n",
      "Epoch: 025/025 | Batch 0150/0469 | Cost: 0.0757\n",
      "Epoch: 025/025 | Batch 0200/0469 | Cost: 0.2176\n",
      "Epoch: 025/025 | Batch 0250/0469 | Cost: 0.0666\n",
      "Epoch: 025/025 | Batch 0300/0469 | Cost: 0.1618\n",
      "Epoch: 025/025 | Batch 0350/0469 | Cost: 0.0685\n",
      "Epoch: 025/025 | Batch 0400/0469 | Cost: 0.1035\n",
      "Epoch: 025/025 | Batch 0450/0469 | Cost: 0.1269\n",
      "Epoch: 025/025 | Train: 89.520%\n",
      "Time elapsed: 19.23 min\n",
      "Total Training Time: 19.23 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets, biases, _) in enumerate(cmnist_train):\n",
    "        \n",
    "        features = features.to(DEVICE).requires_grad_()\n",
    "        targets = targets.to(DEVICE)\n",
    "        biases = biases.to(DEVICE).requires_grad_()\n",
    "            \n",
    "        ## FORWARD AND BACK PROP\n",
    "        \n",
    "        bias_pred, feat_b = model_c(biases)\n",
    "        logits, probas = model(features)\n",
    "        \n",
    "#         cost_bias = F.binary_cross_entropy_with_logits(bias_pred, targets)\n",
    "        \n",
    "        logits_rubi = logits * torch.sigmoid(bias_pred)\n",
    "        cost = nn.CrossEntropyLoss()(logits_rubi, targets) + nn.CrossEntropyLoss()(bias_pred, targets) \n",
    "        \n",
    "#         cost = F.binary_cross_entropy_with_logits(logits, targets) + cost_bias\n",
    "#         cost = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(cmnist_train), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, cmnist_val_unbias, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.52%\n"
     ]
    }
   ],
   "source": [
    "####Test####\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, cmnist_val_unbias, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88.65%\n"
     ]
    }
   ],
   "source": [
    "####Test####\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, cmnist_val_origin, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.82%\n"
     ]
    }
   ],
   "source": [
    "####Test####\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, cmnist_val_bias, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "\n",
    "nhw_img = np.transpose(features[4].expand(3,28,28), axes=(1, 2, 0))\n",
    "plt.imshow(nhw_img);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
