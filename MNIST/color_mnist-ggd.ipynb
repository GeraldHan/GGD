{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "class BiasedMNIST(MNIST):\n",
    "    \"\"\"A base class for Biased-MNIST.\n",
    "    We manually select ten colours to synthetic colour bias. (See `COLOUR_MAP` for the colour configuration)\n",
    "    Usage is exactly same as torchvision MNIST dataset class.\n",
    "\n",
    "    You have two paramters to control the level of bias.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        path to MNIST dataset.\n",
    "    data_label_correlation : float, default=1.0\n",
    "        Here, each class has the pre-defined colour (bias).\n",
    "        data_label_correlation, or `rho` controls the level of the dataset bias.\n",
    "\n",
    "        A sample is coloured with\n",
    "            - the pre-defined colour with probability `rho`,\n",
    "            - coloured with one of the other colours with probability `1 - rho`.\n",
    "              The number of ``other colours'' is controlled by `n_confusing_labels` (default: 9).\n",
    "        Note that the colour is injected into the background of the image (see `_binary_to_colour`).\n",
    "\n",
    "        Hence, we have\n",
    "            - Perfectly biased dataset with rho=1.0\n",
    "            - Perfectly unbiased with rho=0.1 (1/10) ==> our ``unbiased'' setting in the test time.\n",
    "        In the paper, we explore the high correlations but with small hints, e.g., rho=0.999.\n",
    "\n",
    "    n_confusing_labels : int, default=9\n",
    "        In the real-world cases, biases are not equally distributed, but highly unbalanced.\n",
    "        We mimic the unbalanced biases by changing the number of confusing colours for each class.\n",
    "        In the paper, we use n_confusing_labels=9, i.e., during training, the model can observe\n",
    "        all colours for each class. However, you can make the problem harder by setting smaller n_confusing_labels, e.g., 2.\n",
    "        We suggest to researchers considering this benchmark for future researches.\n",
    "    \"\"\"\n",
    "\n",
    "    COLOUR_MAP = [[255, 0, 0], [0, 255, 0], [0, 0, 255], [225, 225, 0], [225, 0, 225],\n",
    "                  [0, 255, 255], [255, 128, 0], [255, 0, 128], [128, 0, 255], [128, 128, 128]]\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9):\n",
    "        super().__init__(root, train=train, transform=transform,\n",
    "                         target_transform=target_transform,\n",
    "                         download=download)\n",
    "        self.random = True\n",
    "\n",
    "        self.data_label_correlation = data_label_correlation\n",
    "        self.n_confusing_labels = n_confusing_labels\n",
    "        self.data, self.targets, self.colored_bg, self.biased_targets = self.build_biased_mnist()\n",
    "\n",
    "        indices = np.arange(len(self.data))\n",
    "        self._shuffle(indices)\n",
    "\n",
    "        self.data = self.data[indices].numpy()\n",
    "        self.colored_bg = self.colored_bg[indices].numpy()\n",
    "        self.targets = self.targets[indices]\n",
    "        self.biased_targets = self.biased_targets[indices]\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, 'processed')\n",
    "\n",
    "    def _shuffle(self, iteratable):\n",
    "        if self.random:\n",
    "            np.random.shuffle(iteratable)\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _update_bias_indices(self, bias_indices, label):\n",
    "        if self.n_confusing_labels > 9 or self.n_confusing_labels < 1:\n",
    "            raise ValueError(self.n_confusing_labels)\n",
    "\n",
    "        indices = np.where((self.targets == label).numpy())[0]\n",
    "        self._shuffle(indices)\n",
    "        indices = torch.LongTensor(indices)\n",
    "\n",
    "        n_samples = len(indices)\n",
    "        n_correlated_samples = int(n_samples * self.data_label_correlation)\n",
    "        n_decorrelated_per_class = int(np.ceil((n_samples - n_correlated_samples) / (self.n_confusing_labels)))\n",
    "\n",
    "        correlated_indices = indices[:n_correlated_samples]\n",
    "        bias_indices[label] = torch.cat([bias_indices[label], correlated_indices])\n",
    "\n",
    "        decorrelated_indices = torch.split(indices[n_correlated_samples:], n_decorrelated_per_class)\n",
    "\n",
    "        other_labels = [_label % 10 for _label in range(label + 1, label + 1 + self.n_confusing_labels)]\n",
    "        self._shuffle(other_labels)\n",
    "\n",
    "        for idx, _indices in enumerate(decorrelated_indices):\n",
    "            _label = other_labels[idx]\n",
    "            bias_indices[_label] = torch.cat([bias_indices[_label], _indices])\n",
    "\n",
    "    def build_biased_mnist(self):\n",
    "        \"\"\"Build biased MNIST.\n",
    "        \"\"\"\n",
    "        n_labels = self.targets.max().item() + 1\n",
    "\n",
    "        bias_indices = {label: torch.LongTensor() for label in range(n_labels)}\n",
    "        for label in range(n_labels):\n",
    "            self._update_bias_indices(bias_indices, label)\n",
    "\n",
    "        data = torch.ByteTensor()\n",
    "        targets = torch.LongTensor()\n",
    "        colored_bg = torch.ByteTensor()\n",
    "        biased_targets = []\n",
    "\n",
    "        for bias_label, indices in bias_indices.items():\n",
    "            (_data, _colored_bg), _targets = self._make_biased_mnist(indices, bias_label)\n",
    "            data = torch.cat([data, _data])\n",
    "            colored_bg = torch.cat([colored_bg, _colored_bg])\n",
    "            targets = torch.cat([targets, _targets])\n",
    "            biased_targets.extend([bias_label] * len(indices))\n",
    "\n",
    "        biased_targets = torch.LongTensor(biased_targets)\n",
    "        return data, targets, colored_bg, biased_targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        colored_bg = self.colored_bg[index]\n",
    "        img = Image.fromarray(img.astype(np.uint8), mode='RGB')\n",
    "        bias = Image.fromarray(colored_bg.astype(np.uint8), mode='RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            bias = self.transform(bias)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        img = np.asarray(img)\n",
    "        bias = np.asarray(bias)\n",
    "        \n",
    "        label = torch.zeros(10)\n",
    "        label.scatter_(0, target, 1)\n",
    "        \n",
    "#         return img, target, bias, int(self.biased_targets[index])\n",
    "        return img, label, bias, int(self.biased_targets[index])\n",
    "\n",
    "\n",
    "class ColourBiasedMNIST(BiasedMNIST):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
    "                 download=False, data_label_correlation=1.0, n_confusing_labels=9):\n",
    "        super(ColourBiasedMNIST, self).__init__(root, train=train, transform=transform,\n",
    "                                                target_transform=target_transform,\n",
    "                                                download=download,\n",
    "                                                data_label_correlation=data_label_correlation,\n",
    "                                                n_confusing_labels=n_confusing_labels)\n",
    "\n",
    "    def _binary_to_colour(self, data, colour):\n",
    "        fg_data = torch.zeros_like(data)\n",
    "        fg_data[data != 0] = 255\n",
    "        fg_data[data == 0] = 0\n",
    "        fg_data = torch.stack([fg_data, fg_data, fg_data], dim=1)\n",
    "\n",
    "        bg_data = torch.zeros_like(data)\n",
    "        bg_data[data == 0] = 1\n",
    "        bg_data[data != 0] = 0\n",
    "        bg_data = torch.stack([bg_data, bg_data, bg_data], dim=3)\n",
    "        bg_data = bg_data * torch.ByteTensor(colour)\n",
    "        \n",
    "        \n",
    "        colored_bg = (bg_data + 1 - bg_data) * torch.ByteTensor(colour)\n",
    "        \n",
    "        bg_data = bg_data.permute(0, 3, 1, 2)\n",
    "        data = fg_data + bg_data\n",
    "        \n",
    "        return data.permute(0, 2, 3, 1), colored_bg\n",
    "\n",
    "    def _make_biased_mnist(self, indices, label):\n",
    "        return self._binary_to_colour(self.data[indices], self.COLOUR_MAP[label]), self.targets[indices]\n",
    "\n",
    "\n",
    "def get_biased_mnist_dataloader(root, batch_size, data_label_correlation,\n",
    "                                n_confusing_labels=9, train=True, num_workers=4):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
    "                             std=(0.5, 0.5, 0.5))])\n",
    "    dataset = ColourBiasedMNIST(root, train=train, transform=transform,\n",
    "                                download=True, data_label_correlation=data_label_correlation,\n",
    "                                n_confusing_labels=n_confusing_labels)\n",
    "    dataloader = data.DataLoader(dataset=dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnist_train = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0.999,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=True)\n",
    "cmnist_val_bias = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0.999,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=False)\n",
    "cmnist_val_unbias = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0.1,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=False)\n",
    "cmnist_val_origin = get_biased_mnist_dataloader(root='data',\n",
    "                                           batch_size=128, \n",
    "                                           data_label_correlation=0,\n",
    "                                          n_confusing_labels=9,\n",
    "                                          train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets, bias, _) in enumerate(cmnist_train):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 28, 28])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "torch.Size([128, 3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(targets[3])\n",
    "print(bias.shape)\n",
    "nhw_img = np.transpose(features[3], axes=(1, 2, 0))\n",
    "plt.imshow(nhw_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAKfklEQVR4nO3dQail9XnH8e+vTrIxQseKw9SYmhZ3WZgibirBLhKsmzGLlLiakMLNopZ0F0kXEUJASpKSVWHSSKYlNQTUOkhpIhJiVsGrWB0zNNowTSYzzCDTUrNKo08X9x25Ge8993re8973mOf7gcs5573nnPfh4Pee9z33Ov9UFZJ++/3O3ANIOhjGLjVh7FITxi41YexSE4cOcmdJ/OhfmlhVZafto2JPcjfwNeAa4B+q6qF9PGbMLiUtsOhX6Vn29+xJrgF+AnwUOAc8C9xXVT9e8Jgydmk6VbXrO/uYc/Y7gFer6qdV9Svg28CxEc8naUJjYr8J+Pm22+eGbb8hyUaSzSSbI/YlaaQx5+w7HSq87Zygqk4AJ8AP6KQ5jXlnPwfcvO32+4Hz48aRNJUxsT8L3Jrkg0neC3wSOLWasSSt2tKH8VX16yT3A99l61dvD1fVyyubTNJKLf2rt6V25q/epElN9as3Se8ixi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjWx9PrsAEnOAq8DbwC/rqrbVzGUpNUbFfvgT6vqtRU8j6QJeRgvNTE29gK+l+S5JBs73SHJRpLNJJsj9yVphFTV8g9Ofr+qzie5EXgK+KuqembB/SvJ0vuTtFhVUVU7Rjbqnb2qzg+Xl4DHgTvGPJ+k6Swde5Jrk1x35TrwMeD0qgaTtFpjPo0/Ajw+HJYfAv65qv5tJVNJWrlR5+zveGees0uTmuycXdK7h7FLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtN7Bl7koeTXEpyetu265M8leSV4fLwtGNKGms/7+zfBO6+atsDwNNVdSvw9HBb0hrbM/aqega4fNXmY8DJ4fpJ4N4VzyVpxQ4t+bgjVXUBoKouJLlxtzsm2QA2ltyPpBVZNvZ9q6oTwAmAJDX1/iTtbNlP4y8mOQowXF5a3UiSprBs7KeA48P148ATqxlH0lRStfjIOskjwF3ADcBF4AvAvwDfAT4A/Az4RFVd/SHeTs9VSUaOLGk3VUVV7RjZnrGvkrFL01oUu39BJzVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhN7xp7k4SSXkpzetu3BJL9I8sLwdc+0Y0oaaz/v7N8E7t5h+99V1W3D17+udixJq7Zn7FX1DHD5AGaRNKEx5+z3J3lxOMw/vNudkmwk2UyyOWJfkkZKVe19p+QW4Mmq+tBw+wjwGlDAF4GjVfXpfTxPJRkzr6QFqoqq2jGypd7Zq+piVb1RVW8CXwfuGDOgpOktFXuSo9tufhw4vdt9Ja2HQ3vdIckjwF3ADUnOAV8A7kpyG1uH8WeBz0w4o6QV2Nc5+8p25jm7NKmVn7NLevcxdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qYk9Y09yc5LvJzmT5OUknx22X5/kqSSvDJeHpx9X0rL2XJ89yVHgaFU9n+Q64DngXuBTwOWqeijJA8DhqvrcHs/l+uzShEatz15VF6rq+eH668AZ4CbgGHByuNtJtn4ASFpTh97JnZPcAnwY+BFwpKouwNYPhCQ37vKYDWBj3JiSxtrzMP6tOybvA34AfKmqHkvyP1X1u9u+/99VtfC83cN4aVqjDuMBkrwHeBT4VlU9Nmy+OJzPXzmvv7SKYSVNYz+fxgf4BnCmqr667VungOPD9ePAE6sfT9Kq7OfT+DuBHwIvAW8Omz/P1nn7d4APAD8DPlFVl/d4Lg/jpQktOozf9zn7Khi7NK3R5+yS3v2MXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJvazPvvNSb6f5EySl5N8dtj+YJJfJHlh+Lpn+nElLWs/67MfBY5W1fNJrgOeA+4F/hz4ZVV9ed87c8lmaVKLlmw+tI8HXwAuDNdfT3IGuGm1I0qa2js6Z09yC/Bh4EfDpvuTvJjk4SSHd3nMRpLNJJujJpU0yp6H8W/dMXkf8APgS1X1WJIjwGtAAV9k61D/03s8h4fx0oQWHcbvK/Yk7wGeBL5bVV/d4fu3AE9W1Yf2eB5jlya0KPb9fBof4BvAme2hDx/cXfFx4PTYQSVNZz+fxt8J/BB4CXhz2Px54D7gNrYO488Cnxk+zFv0XL6zSxMafRi/KsYuTWvUYbyk3w7GLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjWx5z84uWKvVdV/bbt9A1v/tNU6WtfZ1nUucLZlrXK2P9jtGwf6/7O/befJZlXdPtsAC6zrbOs6Fzjbsg5qNg/jpSaMXWpi7thPzLz/RdZ1tnWdC5xtWQcy26zn7JIOztzv7JIOiLFLTcwSe5K7k/xHkleTPDDHDLtJcjbJS8My1LOuTzesoXcpyelt265P8lSSV4bLHdfYm2m2tVjGe8Ey47O+dnMvf37g5+xJrgF+AnwUOAc8C9xXVT8+0EF2keQscHtVzf4HGEk+AvwS+McrS2sl+VvgclU9NPygPFxVn1uT2R7kHS7jPdFsuy0z/ilmfO1Wufz5MuZ4Z78DeLWqflpVvwK+DRybYY61V1XPAJev2nwMODlcP8nWfywHbpfZ1kJVXaiq54frrwNXlhmf9bVbMNeBmCP2m4Cfb7t9jvVa772A7yV5LsnG3MPs4MiVZbaGyxtnnudqey7jfZCuWmZ8bV67ZZY/H2uO2Hdammadfv/3J1X1x8CfAX85HK5qf/4e+CO21gC8AHxlzmGGZcYfBf66qv53zlm222GuA3nd5oj9HHDzttvvB87PMMeOqur8cHkJeJyt0451cvHKCrrD5aWZ53lLVV2sqjeq6k3g68z42g3LjD8KfKuqHhs2z/7a7TTXQb1uc8T+LHBrkg8meS/wSeDUDHO8TZJrhw9OSHIt8DHWbynqU8Dx4fpx4IkZZ/kN67KM927LjDPzazf78ufDqo8H+gXcw9Yn8v8J/M0cM+wy1x8C/z58vTz3bMAjbB3W/R9bR0R/Afwe8DTwynB5/RrN9k9sLe39IlthHZ1ptjvZOjV8EXhh+Lpn7tduwVwH8rr557JSE/4FndSEsUtNGLvUhLFLTRi71ISxS00Yu9TE/wMMIas/pZpAkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bg = np.transpose(bias[3], axes=(1, 2, 0))\n",
    "plt.imshow(bg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # because MNIST is already 1x1 here:\n",
    "        # disable avg pooling\n",
    "        #x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, x\n",
    "\n",
    "\n",
    "\n",
    "def resnet18(num_classes):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[2, 2, 2, 2],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, kernel_size=7, feature_pos='post'):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        layers = [ \n",
    "            nn.Conv2d(3, 16, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        self.extracter = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if feature_pos not in ['pre', 'post', 'logits']:\n",
    "            raise ValueError(feature_pos)\n",
    "\n",
    "        self.feature_pos = feature_pos\n",
    "\n",
    "    def forward(self, x, logits_only=False):\n",
    "        pre_gap_feats = self.extracter(x)\n",
    "        post_gap_feats = self.avgpool(pre_gap_feats)\n",
    "        post_gap_feats = torch.flatten(post_gap_feats, 1)\n",
    "        logits = self.fc(post_gap_feats)\n",
    "\n",
    "        if logits_only:\n",
    "            return logits\n",
    "\n",
    "        elif self.feature_pos == 'pre':\n",
    "            feats = pre_gap_feats\n",
    "        elif self.feature_pos == 'post':\n",
    "            feats = post_gap_feats\n",
    "        else:\n",
    "            feats = logits\n",
    "        return logits, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "\n",
    "model = resnet18(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "# model = SimpleConvNet(kernel_size=7, feature_pos='post').to(DEVICE)\n",
    "\n",
    "model_c = SimpleConvNet(kernel_size=1, feature_pos='post').to(DEVICE)\n",
    "\n",
    "model_r = resnet18(NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# model_c = resnet18(NUM_CLASSES)\n",
    "# model_c.to(DEVICE)\n",
    "\n",
    "# optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': model_c.parameters()}], lr=LEARNING_RATE)  \n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}], lr=LEARNING_RATE)  \n",
    "optimizer_c = torch.optim.Adam(model_c.parameters(), lr=LEARNING_RATE)  \n",
    "optimizer_r = torch.optim.Adam(model_r.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets, bias, _) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = torch.argmax(targets, 1).to(device)\n",
    "        bias = bias.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "#         logits, probas = model(bias)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 0000/0469 | Cost: 0.0003\n",
      "Epoch: 001/020 | Batch 0050/0469 | Cost: 0.0001\n",
      "Epoch: 001/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 001/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 001/020 | Batch 0200/0469 | Cost: 0.0001\n",
      "Epoch: 001/020 | Batch 0250/0469 | Cost: 0.0001\n",
      "Epoch: 001/020 | Batch 0300/0469 | Cost: 0.0084\n",
      "Epoch: 001/020 | Batch 0350/0469 | Cost: 0.0001\n",
      "Epoch: 001/020 | Batch 0400/0469 | Cost: 0.0002\n",
      "Epoch: 001/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 001/020 | Train: 14.900%\n",
      "Time elapsed: 0.81 min\n",
      "Epoch: 002/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 002/020 | Batch 0050/0469 | Cost: 0.0001\n",
      "Epoch: 002/020 | Batch 0100/0469 | Cost: 0.0003\n",
      "Epoch: 002/020 | Batch 0150/0469 | Cost: 0.0014\n",
      "Epoch: 002/020 | Batch 0200/0469 | Cost: 0.0001\n",
      "Epoch: 002/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 002/020 | Batch 0300/0469 | Cost: 0.0031\n",
      "Epoch: 002/020 | Batch 0350/0469 | Cost: 0.0001\n",
      "Epoch: 002/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 002/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 002/020 | Train: 16.970%\n",
      "Time elapsed: 1.61 min\n",
      "Epoch: 003/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 003/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 003/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 003/020 | Batch 0150/0469 | Cost: 0.0002\n",
      "Epoch: 003/020 | Batch 0200/0469 | Cost: 0.0001\n",
      "Epoch: 003/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 003/020 | Batch 0300/0469 | Cost: 0.0012\n",
      "Epoch: 003/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 003/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 003/020 | Batch 0450/0469 | Cost: 0.0002\n",
      "Epoch: 003/020 | Train: 24.290%\n",
      "Time elapsed: 2.39 min\n",
      "Epoch: 004/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 004/020 | Batch 0050/0469 | Cost: 0.0001\n",
      "Epoch: 004/020 | Batch 0100/0469 | Cost: 0.0003\n",
      "Epoch: 004/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 004/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 004/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 004/020 | Batch 0300/0469 | Cost: 0.0009\n",
      "Epoch: 004/020 | Batch 0350/0469 | Cost: 0.0002\n",
      "Epoch: 004/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 004/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 004/020 | Train: 26.480%\n",
      "Time elapsed: 3.18 min\n",
      "Epoch: 005/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 005/020 | Train: 25.590%\n",
      "Time elapsed: 3.94 min\n",
      "Epoch: 006/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0100/0469 | Cost: 0.0003\n",
      "Epoch: 006/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 006/020 | Train: 31.870%\n",
      "Time elapsed: 4.70 min\n",
      "Epoch: 007/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 007/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 007/020 | Batch 0100/0469 | Cost: 0.0002\n",
      "Epoch: 007/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 007/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 007/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 007/020 | Batch 0300/0469 | Cost: 0.0003\n",
      "Epoch: 007/020 | Batch 0350/0469 | Cost: 0.0007\n",
      "Epoch: 007/020 | Batch 0400/0469 | Cost: 0.0001\n",
      "Epoch: 007/020 | Batch 0450/0469 | Cost: 0.0001\n",
      "Epoch: 007/020 | Train: 34.300%\n",
      "Time elapsed: 5.48 min\n",
      "Epoch: 008/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0100/0469 | Cost: 0.0001\n",
      "Epoch: 008/020 | Batch 0150/0469 | Cost: 0.0009\n",
      "Epoch: 008/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 008/020 | Train: 39.890%\n",
      "Time elapsed: 6.25 min\n",
      "Epoch: 009/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 009/020 | Train: 35.060%\n",
      "Time elapsed: 7.01 min\n",
      "Epoch: 010/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0150/0469 | Cost: 0.0001\n",
      "Epoch: 010/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 010/020 | Train: 41.810%\n",
      "Time elapsed: 7.78 min\n",
      "Epoch: 011/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 011/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 011/020 | Batch 0100/0469 | Cost: 0.0004\n",
      "Epoch: 011/020 | Batch 0150/0469 | Cost: 0.0004\n",
      "Epoch: 011/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 011/020 | Batch 0250/0469 | Cost: 0.0001\n",
      "Epoch: 011/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 011/020 | Batch 0350/0469 | Cost: 0.0001\n",
      "Epoch: 011/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 011/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 011/020 | Train: 43.880%\n",
      "Time elapsed: 8.55 min\n",
      "Epoch: 012/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Batch 0100/0469 | Cost: 0.0001\n",
      "Epoch: 012/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Batch 0350/0469 | Cost: 0.0001\n",
      "Epoch: 012/020 | Batch 0400/0469 | Cost: 0.0001\n",
      "Epoch: 012/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 012/020 | Train: 46.540%\n",
      "Time elapsed: 9.34 min\n",
      "Epoch: 013/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 013/020 | Batch 0450/0469 | Cost: 0.0006\n",
      "Epoch: 013/020 | Train: 46.950%\n",
      "Time elapsed: 10.15 min\n",
      "Epoch: 014/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0100/0469 | Cost: 0.0001\n",
      "Epoch: 014/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Batch 0400/0469 | Cost: 0.0001\n",
      "Epoch: 014/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 014/020 | Train: 46.710%\n",
      "Time elapsed: 10.95 min\n",
      "Epoch: 015/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0150/0469 | Cost: 0.0002\n",
      "Epoch: 015/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 015/020 | Train: 57.850%\n",
      "Time elapsed: 11.81 min\n",
      "Epoch: 016/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 016/020 | Train: 57.170%\n",
      "Time elapsed: 12.59 min\n",
      "Epoch: 017/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 017/020 | Train: 57.200%\n",
      "Time elapsed: 13.31 min\n",
      "Epoch: 018/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 018/020 | Train: 56.880%\n",
      "Time elapsed: 14.04 min\n",
      "Epoch: 019/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 019/020 | Train: 57.110%\n",
      "Time elapsed: 14.81 min\n",
      "Epoch: 020/020 | Batch 0000/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0050/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0100/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0150/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0200/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0250/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0300/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0350/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0400/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Batch 0450/0469 | Cost: 0.0000\n",
      "Epoch: 020/020 | Train: 57.430%\n",
      "Time elapsed: 15.56 min\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "####Training#######\n",
    "celoss = nn.CrossEntropyLoss(reduction='none')\n",
    "start_time = time.time()\n",
    "\n",
    "base_ratio = []\n",
    "gge_ratio = []\n",
    "\n",
    "gge_gradient = []\n",
    "base_gradient = []\n",
    "\n",
    "gge_hard_loss = []\n",
    "base_hard_loss = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    weight = math.sin(math.pi/2 * (epoch+10) / (NUM_EPOCHS+10)) \n",
    "    model.train()\n",
    "    model_c.train()\n",
    "    \n",
    "    base_cost_mask_sum = 0\n",
    "    base_cost_sum = 0\n",
    "    \n",
    "    gge_cost_mask_sum = 0\n",
    "    gge_cost_sum = 0\n",
    "    \n",
    "    gge_gradient_sum = 0\n",
    "    base_gradient_sum = 0\n",
    "    \n",
    "    for batch_idx, (features, targets, biases, bias_label) in enumerate(cmnist_train):\n",
    "        \n",
    "        \n",
    "        features = features.to(DEVICE).requires_grad_()\n",
    "        targets = targets.to(DEVICE)\n",
    "        biases = biases.to(DEVICE).requires_grad_()\n",
    "        bias_label = bias_label.to(DEVICE)\n",
    "        \n",
    "        mask = 1. - (torch.argmax(targets, 1) == bias_label).byte()\n",
    "            \n",
    "        ## FORWARD AND BACK PROP\n",
    "        \n",
    "        bias_pred, feat_b = model_c(features)\n",
    "#         cost_bias = F.binary_cross_entropy_with_logits(bias_pred, targets)\n",
    "        cost_bias = -(targets * bias_pred.log_softmax(-1)).mean()\n",
    "\n",
    "        \n",
    "        optimizer_c.zero_grad()\n",
    "        cost_bias.backward() \n",
    "        optimizer_c.step()\n",
    "        \n",
    "        \n",
    "        logits, feats = model(features)\n",
    "#         cost = -(targets * logits.log_softmax(1)).mean()\n",
    "        \n",
    "        cost = -(targets * logits.log_softmax(1)).mean(-1) + weight * (targets * bias_pred.detach().softmax(1) * logits.log_softmax(1)).mean(-1)\n",
    "#         cost  = -(y_gradient * logits.log_softmax(1)).mean(-1)\n",
    "        \n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        logits_r, feat_r = model_r(features)\n",
    "        cost_r = -(targets * logits_r.log_softmax(-1)).mean(-1)\n",
    "        \n",
    "        base_cost_mask_sum += (cost_r * mask).float().sum(0).item()\n",
    "        base_cost_sum += cost_r.float().sum(0).item()\n",
    "        \n",
    "        \n",
    "        base_grad=torch.autograd.grad(cost_r.mean(), feat_r, create_graph=True)[0].float().sum(0).detach().cpu().numpy()\n",
    "        \n",
    "        base_gradient_sum += base_grad\n",
    "        \n",
    "        optimizer_r.zero_grad()\n",
    "        cost_r.mean().backward()\n",
    "        optimizer_r.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(cmnist_train), cost.mean()))\n",
    "            \n",
    "#         if not (batch_idx+1) % 118:\n",
    "#             print(gge_cost_mask_sum/gge_cost_sum)\n",
    "#             gge_ratio.append(gge_cost_mask_sum/gge_cost_sum)\n",
    "#             base_ratio.append(base_cost_mask_sum/base_cost_sum)\n",
    "\n",
    "#             base_gradient.append(base_gradient_sum)\n",
    "#             gge_gradient.append(gge_gradient_sum)\n",
    "\n",
    "#             gge_hard_loss.append(gge_cost_mask_sum / 124)\n",
    "#             base_hard_loss.append(base_cost_mask_sum / 124)\n",
    "\n",
    "#             base_cost_mask_sum = 0\n",
    "#             base_cost_sum = 0\n",
    "\n",
    "#             gge_cost_mask_sum = 0\n",
    "#             gge_cost_sum = 0\n",
    "\n",
    "#             gge_gradient_sum = 0\n",
    "#             base_gradient_sum = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, cmnist_val_unbias, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 57.43%\n"
     ]
    }
   ],
   "source": [
    "####Test####\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, cmnist_val_unbias, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 53.05%\n"
     ]
    }
   ],
   "source": [
    "####Test####\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, cmnist_val_origin, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.93%\n"
     ]
    }
   ],
   "source": [
    "####Test####\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, cmnist_val_bias, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 24.35%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model_r, cmnist_val_origin, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANQklEQVR4nO3dYaxU9ZnH8d9vpcVIifEugSWUSJf4QiNZUWI0klXTFBUTsVE3ELKhavb2RU3auC/W6ItqjIkxW8y+keQ2mtJNV9IoRlKbbQ1gXd80XJUK9m4rErZQCIiEFIymCs++uAdzxTtnLnPOmTOX5/tJbmbmPHNmnhz9cf4z/5n5OyIE4Pz3N203AKA/CDuQBGEHkiDsQBKEHUhiRj+fzDZv/QMNiwhPtr3Smd32rbb/YHuP7YeqPBaAZrnXeXbbF0j6o6RvSTogaYekNRHx+5J9OLMDDWvizH6tpD0RsTci/ippk6RVFR4PQIOqhH2BpP0Tbh8otn2B7WHbo7ZHKzwXgIqqvEE32VDhS8P0iBiRNCIxjAfaVOXMfkDSwgm3vy7pYLV2ADSlSth3SLrM9jdsf1XSaklb6mkLQN16HsZHxGe2H5D0K0kXSHouIt6trTMAtep56q2nJ+M1O9C4Rj5UA2D6IOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJnpdsRv9cffXVpfXNmzd3rC1atKjmbgbHihUrSutjY2Mda/v376+7nYFXKey290k6IemUpM8iYlkdTQGoXx1n9psj4mgNjwOgQbxmB5KoGvaQ9Gvbb9oenuwOtodtj9oerfhcACqoOoy/ISIO2p4r6VXb/xsRr0+8Q0SMSBqRJNtR8fkA9KjSmT0iDhaXRyS9JOnaOpoCUL+ew257lu3ZZ65LWiFpd12NAahXlWH8PEkv2T7zOP8VEf9dS1f4gltuuaW0PnPmzD51MljuuOOO0vp9993XsbZ69eq62xl4PYc9IvZK+ocaewHQIKbegCQIO5AEYQeSIOxAEoQdSIKvuA6AGTPK/zOsXLmyT51ML6Oj5Z/AfvDBBzvWZs2aVbrvRx991FNPg4wzO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTz7ALj55ptL69dff31p/amnnqqznWljaGiotH7FFVd0rF100UWl+zLPDmDaIuxAEoQdSIKwA0kQdiAJwg4kQdiBJBzRv0Vasq4Is2TJktL69u3bS+sffvhhaf2aa67pWDt58mTpvtPZa6+9Vlpfvnx5x9r8+fNL9/3ggw96aWkgRIQn286ZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4PvsffDII4+U1rv9hvltt91WWj9f59K7fV/9xhtvLK2fPn26znamva5ndtvP2T5ie/eEbUO2X7X9XnF5SbNtAqhqKsP4n0i69axtD0naGhGXSdpa3AYwwLqGPSJel3TsrM2rJG0srm+UdGfNfQGoWa+v2edFxCFJiohDtud2uqPtYUnDPT4PgJo0/gZdRIxIGpHyfhEGGAS9Tr0dtj1fkorLI/W1BKAJvYZ9i6R1xfV1kl6upx0ATek6jLf9vKSbJM2xfUDSDyU9Kenntu+X9CdJ9zTZ5KC7++67S+vd1lffs2dPaX3Hjh3n3NP5oNvnE7rNo5d93/348eO9tDStdQ17RKzpUPpmzb0AaBAflwWSIOxAEoQdSIKwA0kQdiAJvuJag3vuKZ957LY88IYNG+psZ9pYtGhRaX3t2rWl9VOnTpXWn3jiiY61Tz/9tHTf8xFndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ignn2Kbr44os71q677rpKj/3MM89U2n+6Gh4u/7WyOXPmlNbHxsZK69u2bTvnns5nnNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnm2ado5syZHWsLFiwo3XfTpk11t3NeWLx4caX9d+/e3f1O+BxndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ignn2KTpx4kTH2s6dO0v3XbJkSWl9aGiotH7s2LHS+iCbO3dux1q3pa67eeONNyrtn03XM7vt52wfsb17wrZHbf/Z9s7ir3wBcgCtm8ow/ieSbp1k+9MRcVXx98t62wJQt65hj4jXJU3fcSQASdXeoHvA9jvFMP+STneyPWx71PZohecCUFGvYd8gabGkqyQdkvSjTneMiJGIWBYRy3p8LgA16CnsEXE4Ik5FxGlJP5Z0bb1tAahbT2G3PX/CzW9L4ruGwIDrOs9u+3lJN0maY/uApB9Kusn2VZJC0j5J322wx4Hw8ccfd6y9//77pfveddddpfVXXnmltL5+/frSepOuvPLK0nq376RfeumlHWsR0VNPde2fTdewR8SaSTY/20AvABrEx2WBJAg7kARhB5Ig7EAShB1Iwv2cvrB9Xs6VXH755aX1xx57rLR+++23l9bLfsa6aUePHi2td/v/p2zZZds99XTG7NmzS+tl06Xns4iY9MByZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJhnHwBLly4trVdd2riKF154odL+Gzdu7Fhbu3ZtpceeMYNfQp8M8+xAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kAQTlQPg7bffrlQfZHv37m3ssbsthb1r167Gnns64swOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwz45Glf02fNXfjWce/dx0PbPbXmh7u+0x2+/a/n6xfcj2q7bfKy4vab5dAL2ayjD+M0n/GhGXS7pO0vdsXyHpIUlbI+IySVuL2wAGVNewR8ShiHiruH5C0pikBZJWSTrzm0MbJd3ZVJMAqjun1+y2F0laKum3kuZFxCFp/B8E23M77DMsabhamwCqmnLYbX9N0ouSfhARf5nqmysRMSJppHgMfnASaMmUpt5sf0XjQf9ZRGwuNh+2Pb+oz5d0pJkWAdRhKu/GW9KzksYiYv2E0hZJ64rr6yS9XH97mO4iorE/nJupDONvkPTPknbZ3llse1jSk5J+bvt+SX+SdE8zLQKoQ9ewR8Qbkjq9QP9mve0AaAoflwWSIOxAEoQdSIKwA0kQdiAJvuKKRl144YU97/vJJ5/U2Ak4swNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEsyzo1H33ntvx9rx48dL93388cfrbic1zuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7GjUjh07Otaefvrp0n23bdtWdzupcWYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTcbZ1r2wsl/VTS30k6LWkkIv7D9qOS/kXSB8VdH46IX3Z5LBbVBhoWEZOuujyVsM+XND8i3rI9W9Kbku6U9E+STkbEv0+1CcIONK9T2KeyPvshSYeK6ydsj0laUG97AJp2Tq/ZbS+StFTSb4tND9h+x/Zzti/psM+w7VHbo5U6BVBJ12H853e0vybpN5KeiIjNtudJOiopJD2u8aH+fV0eg2E80LCeX7NLku2vSPqFpF9FxPpJ6osk/SIiruzyOIQdaFinsHcdxtu2pGcljU0MevHG3RnflrS7apMAmjOVd+OXS/ofSbs0PvUmSQ9LWiPpKo0P4/dJ+m7xZl7ZY3FmBxpWaRhfF8IONK/nYTyA8wNhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiX4v2XxU0v9NuD2n2DaIBrW3Qe1Lorde1dnbpZ0Kff0++5ee3B6NiGWtNVBiUHsb1L4keutVv3pjGA8kQdiBJNoO+0jLz19mUHsb1L4keutVX3pr9TU7gP5p+8wOoE8IO5BEK2G3favtP9jeY/uhNnroxPY+27ts72x7fbpiDb0jtndP2DZk+1Xb7xWXk66x11Jvj9r+c3Hsdtpe2VJvC21vtz1m+13b3y+2t3rsSvrqy3Hr+2t22xdI+qOkb0k6IGmHpDUR8fu+NtKB7X2SlkVE6x/AsP2Pkk5K+umZpbVsPyXpWEQ8WfxDeUlE/NuA9PaoznEZ74Z667TM+HfU4rGrc/nzXrRxZr9W0p6I2BsRf5W0SdKqFvoYeBHxuqRjZ21eJWljcX2jxv9n6bsOvQ2EiDgUEW8V109IOrPMeKvHrqSvvmgj7Ask7Z9w+4AGa733kPRr22/aHm67mUnMO7PMVnE5t+V+ztZ1Ge9+OmuZ8YE5dr0sf15VG2GfbGmaQZr/uyEirpZ0m6TvFcNVTM0GSYs1vgbgIUk/arOZYpnxFyX9ICL+0mYvE03SV1+OWxthPyBp4YTbX5d0sIU+JhURB4vLI5Je0vjLjkFy+MwKusXlkZb7+VxEHI6IUxFxWtKP1eKxK5YZf1HSzyJic7G59WM3WV/9Om5thH2HpMtsf8P2VyWtlrSlhT6+xPas4o0T2Z4laYUGbynqLZLWFdfXSXq5xV6+YFCW8e60zLhaPnatL38eEX3/k7RS4+/Ivy/pkTZ66NDX30v6XfH3btu9SXpe48O6TzU+Irpf0t9K2irpveJyaIB6+0+NL+39jsaDNb+l3pZr/KXhO5J2Fn8r2z52JX315bjxcVkgCT5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D8Ux0NdsVzeMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "\n",
    "nhw_img = np.transpose(features[4].expand(3,28,28), axes=(1, 2, 0))\n",
    "plt.imshow(nhw_img);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
